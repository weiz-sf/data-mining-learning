{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSiTTN27YBT5"
   },
   "source": [
    "#  Homework 6 for CS 247 : Advanced Data Mining Learning\n",
    "\n",
    "\n",
    "### Due: 11:59 pm 05/20\n",
    "\n",
    "##### Please read the Homework Guidance (uploaded to CCLE) carefully and make sure you fulfill all the requirements.\n",
    "\n",
    "\n",
    "\n",
    "__Name__: [Your name]\n",
    "\n",
    "__UID__: [Your uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfaybVLdYBT6"
   },
   "source": [
    "## Problem 1: Spectral Clustering (35 pts)\n",
    "\n",
    "In this problem, you are going to prove a property of the unormalized graph Laplacian matrix. Then, you are going to implement the spectral clustering and apply it on the Karate Club dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Property of Unnormalized Graph Laplacian (10 pts)\n",
    "\n",
    "Given a unnormalized graph Laplacian matrix $L=D-W$, prove that for every vector $f \\in R^n$, we have:\n",
    "\n",
    "$$\n",
    "f^T L f = \\frac{1}{2}\\sum_{ij} w_{ij}(f_i - f_j) ^ 2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JibxbFWHYBT7"
   },
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8wJ7ZBwYBT8"
   },
   "source": [
    "### Part 2: Implement Spectral Clustering (25pts = 10 + 15)\n",
    "\n",
    "In this part, you are going to implement the spectral clustering model, and get two clusters of the Karate club graph, then visialize them. You are allowed to use the sklearn implementation of Kmeans.\n",
    "\n",
    "Hint:\n",
    "1. Please refer to the official documentation if you want to get familiar with the networkx library: https://networkx.org/documentation/stable/tutorial.html\n",
    "2. You may find this link helpful if you want to know more about the Karate Club dataset: https://networkx.org/documentation/networkx-1.10/reference/generated/networkx.generators.social.karate_club_graph.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqgCxQAUYBT8"
   },
   "outputs": [],
   "source": [
    "# import neccessary libraries\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm \n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "DNrVAs-NYBUH",
    "outputId": "7f73bfbe-a7d1-49c1-9da6-184d0d8750e3"
   },
   "outputs": [],
   "source": [
    "# load and preprocess the Karate Club Graph\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "nx.draw(G, with_labels=True, pos=nx.spring_layout(G))\n",
    "\n",
    "A = nx.adj_matrix(G)\n",
    "A = A.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3gulSGQeYBUL",
    "outputId": "87ce7258-4275-45d4-b573-b19bf8c528b6"
   },
   "outputs": [],
   "source": [
    "def laplacian(A):\n",
    "    \"\"\"\n",
    "        TODO: \n",
    "            Computes the symetric normalized laplacian.\n",
    "                 L = D^{-1/2} A D{-1/2}\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(adjacency, n_clusters):\n",
    "    k_means = KMeans(n_clusters=n_clusters, random_state=43)\n",
    "    \"\"\"\n",
    "        TODO: \n",
    "            Spectral Clustering method, please return the labels.\n",
    "            You can follow these steps:\n",
    "                (1) Calculate the lapalacian matrix of the adjacency matrix.\n",
    "                (2) Get the eigen vector of this laplacian matrix, then normalize it.\n",
    "                (3) Get the cluster label using kmeans.     \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# use the spectral clustering method on Karate Club Graph\n",
    "labels = spectral_clustering(A, 2)\n",
    "print(labels) # Please keep this output in your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "S2hHgy-FYBUV",
    "outputId": "1f22b4ec-efb4-4630-d940-c9a2dd630e2a"
   },
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "\n",
    "r_nodes = []\n",
    "b_nodes = []\n",
    "for i, j in enumerate(labels):\n",
    "    if j == 0:\n",
    "        r_nodes += [i]\n",
    "    else:\n",
    "        b_nodes += [i]\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos, with_labels=True,\n",
    "                       nodelist=r_nodes,\n",
    "                       node_color='r',\n",
    "                       node_size=500,\n",
    "                   alpha=0.8)\n",
    "nx.draw(G,pos, with_labels=True,\n",
    "                       nodelist=b_nodes,\n",
    "                       node_color='b',\n",
    "                       node_size=500,\n",
    "                   alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Normalized Cut (35pts)\n",
    "\n",
    "In this problem, you are going to prove some properties of the Normalized Cut.\n",
    "\n",
    "Consider the problem of partitioning a graph G = (V,E) into two subgraphs with similar sizes. Let A ⊆ V and B ⊆ V denote the disjoint node sets of the two clusters. Let cut(A, B) denote the total number of edges or total weight of edges that separate the two clusters, i.e., cut(A,B) = $\\Sigma_{i∈A,j∈B}$ wij, where wij denotes the weight associated with edge between i and j. Let dX = $\\Sigma_{i∈X}$ di be the total degree of nodes in cluster X, the normalized cut between two clusters is defined as:\n",
    "\n",
    "$Ncut(A,B)=\\frac{cut(A,B)}{d_A}+\\frac{cut(B,A)}{d_B}$\n",
    "\n",
    "Let f be the cluster indicator vector, where:\n",
    "$f=\\begin{cases} \n",
    "\\sqrt{\\frac{d_B}{d_A}} & if\\ i\\in A\\\\\n",
    "-\\sqrt{\\frac{d_A}{d_B}} & if\\ i\\in B\n",
    "\\end{cases}$\n",
    "\n",
    "Let D be the diagonal matrix with Dii = $\\Sigma_j w_{ij}$, and 0 elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 (5pts)\n",
    "\n",
    "Please prove: $(Df)^T 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (5pts)\n",
    "\n",
    "Please prove: $f^TDf = d_V$ , where $d_V$ is the total degree of all the nodes in the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 (10pts)\n",
    "\n",
    "Please prove: $f^TLf = d_V Ncut(A,B)$, where L is the unnormalized graph Laplacian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 (15pts)\n",
    "Prove the solution of f is the second eigenvector of $L_rw$. \n",
    "\n",
    "Hint: \n",
    "With part 1~3, we can relax f to a real vector, and the goal is to find f to minimize $f^TLf$, with the constraint part 1 and part 2 hold. Then, let $g = D^{1/2}f$, substitute f with g in the aforementioned objective function and constraints. Finally, prove the solution of g is the second eigenvector of Lsym.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCSC_lM1YBUe"
   },
   "source": [
    "## Problem 3: Node Embedding - LINE (30 pts = 20 + 10)\n",
    "\n",
    "\n",
    "In this problem, you are going to implement the First-order LINE (finish contrastive loss, negative sampling and training pipleline). Get embedding of karate graph, then visualize your results.\n",
    "\n",
    "Hint: Please refer to slide 09 - Graph and Network: Graph Embedding, page 8-12 for the details of the LINE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "Io6IdRB0YBUj",
    "outputId": "638b473a-c3c5-43d9-ca9f-4b43e07ea2c1"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sb\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm \n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set parameters\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "edges  = np.array(list(G.edges))\n",
    "degree = dict(G.degree)\n",
    "true_labels = np.zeros(len(G.node))\n",
    "for i in range(len(labels)):\n",
    "    if G.node[i]['club']=='Officer':\n",
    "        true_labels[i]=1\n",
    "\n",
    "n_epochs = 100\n",
    "neg_size = 5\n",
    "batchrange = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVFAk2jNYBUm"
   },
   "outputs": [],
   "source": [
    "class Line(nn.Module):\n",
    "    def __init__(self, size, embed_dim=128):\n",
    "        super(Line, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.nodes_embeddings = nn.Embedding(size, embed_dim)\n",
    "\n",
    "        # Initialization\n",
    "        self.nodes_embeddings.weight.data = self.nodes_embeddings.weight.data.uniform_(-.5, .5) / embed_dim\n",
    "\n",
    "    def loss(self, v_i, v_j, negsamples):\n",
    "        '''\n",
    "            TODO: \n",
    "                Similar to Skip-gram implementaion, implement contrastive loss here\n",
    "        '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     generating batches of data.\n",
    "\n",
    "def makeData(samplededges, negsamplesize, degree):\n",
    "    sampledNodes = set()\n",
    "    nodesProb = []\n",
    "    sumofDegree = 0\n",
    "    for e in samplededges:\n",
    "        sampledNodes.add(e[0])\n",
    "        sampledNodes.add(e[1])\n",
    "    sampledNodes = list(sampledNodes)\n",
    "    nodesProb = [pow(degree[v],3/4) for v in sampledNodes]\n",
    "    sumofDegree = sum(nodesProb)\n",
    "    nodesProb[:] = [x/sumofDegree for x in nodesProb]\n",
    "\n",
    "    for e in samplededges:\n",
    "        sourcenode, targetnode = e[0], e[1]\n",
    "        negnodes = []\n",
    "        negsamples = 0\n",
    "        while negsamples < negsamplesize:\n",
    "            '''\n",
    "                TODO: \n",
    "                    Randomly sampled negative nodes based on degree (d^{3/4})\n",
    "            '''\n",
    "            samplednode = \n",
    "            \n",
    "            \n",
    "            if (samplednode == sourcenode) or (samplednode == targetnode):\n",
    "                continue\n",
    "            else:\n",
    "                negsamples += 1\n",
    "                negnodes += [samplednode]\n",
    "        yield [e[0], e[1]] + negnodes\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "line = Line(len(G), embed_dim=100)\n",
    "opt = optim.Adam(line.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    for b in trange(batchrange):\n",
    "        opt.zero_grad()\n",
    "        edge_idx = np.random.choice(len(edges), 10)\n",
    "        samplededges = edges[edge_idx]\n",
    "        \n",
    "        batch = list(makeData(samplededges, neg_size, degree))\n",
    "        batch = torch.LongTensor(batch)\n",
    "        \n",
    "        # based on the generated batch, train LINE via minimizing the loss.\n",
    "        v_i = batch[:,0]\n",
    "        v_j = batch[:,1]\n",
    "        negsamples =  batch[:,2:]\n",
    "        loss = line.loss(v_i, v_j, negsamples)\n",
    "        loss.backward()\n",
    "        opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE visualization, with node id on\n",
    "\n",
    "emb  = line.nodes_embeddings.weight.data.numpy()\n",
    "tsne_emb = TSNE(n_components = 2, perplexity = 5, learning_rate = 10).fit_transform(emb)\n",
    "\n",
    "plt.scatter(tsne_emb[:,0], tsne_emb[:,1], c=true_labels)\n",
    "for i in range(len(tsne_emb)):\n",
    "    plt.annotate(str(i), xy=(tsne_emb[i,0], tsne_emb[i,1]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap visualization, check cosine similarities between all pair of nodes\n",
    "\n",
    "res = cosine_similarity(emb) \n",
    "sb.clustermap(res)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
